{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"interpreter":{"hash":"d7f94b8b1e41b02170d45ac71ce2d6b011e7cd56207b4c480f5292088bcfab93"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Background\n\nICESat-2 is a space-based laser altimetry mission that provides accurate 3-D representations of the earthâ€™s surface. The Advanced Topographic Laser Altimeter System (ATLAS) onboard ICESat-2 can measure surface heights with great accuracy, providing critical measurements needed to better understand key surface structure variables.\n\n### ATL03\nThe ATL03 data set (https://nsidc.org/data/atl03/versions/6) contains height above the WGS 84 ellipsoid (ITRF2014 reference frame), latitude, longitude, and time for all photons downlinked by the Advanced Topographic Laser Altimeter System (ATLAS) instrument on board the Ice, Cloud and land Elevation Satellite-2 (ICESat-2) observatory. The ATL03 product was designed to be a single source for all photon data and ancillary information needed by higher-level ATLAS/ICESat-2 products. As such, it also includes spacecraft and instrument parameters and ancillary data not explicitly required for ATL03.\n\n### ATL06\nThe ATL06 data set (https://nsidc.org/data/atl06/versions/6) provides geolocated, land-ice surface heights (above the WGS 84 ellipsoid, ITRF2014 reference frame), plus ancillary parameters that can be used to interpret and assess the quality of the height estimates. The data were also acquired by the ATLAS instrument on board ICESat-2.\n\n## The goal of this demo\n\nProcess a single ATL03 granule using SlideRule's ATL06-SR algorithm and compare the results to the existing ATL06 data product.\n\n### What is demonstrated\n\n* The `icesat2.atl06` Application Programming Interface (API) is used to perform a SlideRule processing request of a single ATL03 granule\n* The `h5.h5p` API is used to read existing ATL06 datasets\n* The `matplotlib` package is used to plot the elevation profile of all three tracks in the granule (with the first track overlaid with the expected profile)\n* The `geopandas` package is used to produce a plot representing the geolocation of the elevations produced by SlideRule.\n\n### Points of interest\n\nMost use cases for SlideRule use the higher level `icesat2.atl06p` API which works on a region of interest; but this notebook shows some of the capabilities of SlideRule for working on individual granules.","metadata":{"trusted":true}},{"cell_type":"code","source":"# Suppress Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport posixpath\nimport shapely.geometry\nimport geopandas as gpd\nimport numpy as np # Numeric Python\nimport matplotlib.pyplot as plt # Plotting routines\nimport matplotlib.dates as mdates\nfrom sliderule import icesat2, io, sliderule, earthdata, h5","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configure Session\nicesat2.init(\"slideruleearth.io\")","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Find ATL03 Granules","metadata":{"trusted":true}},{"cell_type":"code","source":"# find granules for a spatial and temporal query\nbox_lon = [-105, -105, -100, -100, -105]\nbox_lat = [-75, -77.5, -77.5, -75, -75]\npoly = io.to_region(box_lon, box_lat)\nresources = earthdata.cmr(short_name='ATL03', polygon=poly, time_start='2018-10-19', time_end='2018-10-20') \ngranule = resources[0]","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Execute SlideRule Algorithm","metadata":{"trusted":true}},{"cell_type":"code","source":"%%time\n# regular expression operator for extracting information from files\nrx = re.compile(r'(ATL\\d{2})(-\\d{2})?_(\\d{4})(\\d{2})(\\d{2})(\\d{2})'\n    r'(\\d{2})(\\d{2})_(\\d{4})(\\d{2})(\\d{2})_(\\d{3})_(\\d{2})(.*?).h5$')\n# extract parameters from ICESat-2 granule\nPRD,HEM,YY,MM,DD,HH,MN,SS,TRK,CYCL,GRN,RL,VRS,AUX=rx.findall(granule).pop()\n\n# Build ATL06 Request\nparms = {\n    \"poly\":poly,  # polygon defining region of interest\n    \"cnf\": 4,     # confidence level for photon selection\n    \"ats\": 20.0,  # minimum along track spread\n    \"cnt\": 10,    # minimum photon count in segment\n    \"len\": 40.0,  # length of each extent in meters\n    \"res\": 20.0   # step distance for successive extents in meters\n}\n\n# Request ATL06 Data\ngdf = icesat2.atl06(parms, granule)\n\n# Return DataFrame\nprint(\"Reference Ground Tracks: {} to {}\".format(min(gdf[\"rgt\"]), max(gdf[\"rgt\"])))\nprint(\"Cycle: {} to {}\".format(min(gdf[\"cycle\"]), max(gdf[\"cycle\"])))\nprint(\"Retrieved {} points from SlideRule\".format(len(gdf[\"h_mean\"])))","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define function to return granules\ndef s3_retrieve(granule, **kwargs):\n    \n    # set default keyword arguments\n    kwargs.setdefault('lon_key','longitude')\n    kwargs.setdefault('lat_key','latitude')\n    kwargs.setdefault('index_key','time')\n    kwargs.setdefault('polygon',None)\n    \n    # regular expression operator for extracting information from files\n    rx = re.compile(r'(ATL\\d{2})(-\\d{2})?_(\\d{4})(\\d{2})(\\d{2})(\\d{2})'\n        r'(\\d{2})(\\d{2})_(\\d{4})(\\d{2})(\\d{2})_(\\d{3})_(\\d{2})(.*?).h5$')\n    \n    # extract parameters from ICESat-2 granule\n    PRD,HEM,YY,MM,DD,HH,MN,SS,TRK,CYCL,GRN,RL,VRS,AUX=rx.findall(granule).pop()\n    \n    # variables of interest\n    if (PRD == 'ATL06'):\n        segment_group = \"land_ice_segments\"\n        segment_key = 'segment_id'\n        vnames = ['segment_id','delta_time','latitude','longitude',\n            'h_li','h_li_sigma','atl06_quality_summary',\n            'fit_statistics/dh_fit_dx','fit_statistics/dh_fit_dy',\n            'fit_statistics/dh_fit_dx_sigma','fit_statistics/n_fit_photons',\n            'fit_statistics/h_expected_rms','fit_statistics/h_robust_sprd',\n            'fit_statistics/w_surface_window_final','fit_statistics/h_mean']\n    elif (PRD == 'ATL08'):\n        segment_group = \"land_segments\"\n        segment_key = 'segment_id_beg'\n        vnames = ['segment_id_beg','segment_id_end','delta_time',\n            'latitude','longitude','brightness_flag','layer_flag',\n            'msw_flag','night_flag','terrain_flg','urban_flag',\n            'segment_landcover','segment_snowcover','segment_watermask',\n            'terrain/h_te_best_fit','terrain/h_te_uncertainty',\n            'terrain/terrain_slope','terrain/n_te_photons',\n            'canopy/h_canopy','canopy/h_canopy_uncertainty',\n            'canopy/canopy_flag','canopy/n_ca_photons']\n    \n    # for each valid beam within the HDF5 file\n    frames = []\n    gt = dict(gt1l=10,gt1r=20,gt2l=30,gt2r=40,gt3l=50,gt3r=60)\n    atlas_sdp_epoch = np.datetime64('2018-01-01T00:00:00')\n    kwds = dict(startrow=0,numrows=-1)\n    for gtx in ['gt1l','gt1r','gt2l','gt2r','gt3l','gt3r']:\n        geodatasets = [dict(dataset=f'{gtx}/{segment_group}/{v}',**kwds) for v in vnames]\n        try:\n            # get datasets from s3\n            hidatasets = h5.h5p(geodatasets, granule, \"icesat2\")\n            # copy to new \"flattened\" dictionary\n            data = {posixpath.basename(key):var for key,var in hidatasets.items()}\n            # Generate Time Column\n            delta_time = (data['delta_time']*1e9).astype('timedelta64[ns]')\n            data['time'] = gpd.pd.to_datetime(atlas_sdp_epoch + delta_time)\n        except:\n            pass\n        else:\n            # copy filename parameters\n            data['rgt'] = [int(TRK)]*len(data['delta_time'])\n            data['cycle'] = [int(CYCL)]*len(data['delta_time'])\n            data['gt'] = [gt[gtx]]*len(data['delta_time'])\n            # pandas dataframe from compiled dictionary\n            frames.append(gpd.pd.DataFrame.from_dict(data))\n    \n    # concatenate pandas dataframe\n    try:\n        df = gpd.pd.concat(frames)\n    except:\n        return sliderule.emptyframe()\n    \n    # convert to a GeoDataFrame\n    lon_key,lat_key = (kwargs['lon_key'],kwargs['lat_key'])\n    geometry = gpd.points_from_xy(df[lon_key], df[lat_key])\n    gdf = gpd.GeoDataFrame(df.drop(columns=[lon_key,lat_key]),\n        geometry=geometry,crs='EPSG:4326')\n    \n    # intersect with geometry in projected reference system\n    if kwargs['polygon'] is not None:\n        gdf = gpd.overlay(gdf.to_crs(kwargs['polygon'].crs),\n            kwargs['polygon'], how='intersection')\n    \n    # sort values for reproducible output despite async processing\n    gdf.set_index(kwargs['index_key'], inplace=True)\n    gdf.sort_index(inplace=True)\n    \n    # remove duplicate points\n    gdf = gdf[~gdf.index.duplicated()]\n    \n    # convert back to original coordinate reference system\n    return gdf.to_crs('EPSG:4326')","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get standard ATL06 products\natl06_granule = f'ATL06_{YY}{MM}{DD}{HH}{MN}{SS}_{TRK}{CYCL}{GRN}_{RL}_{VRS}{AUX}.h5'\nregion_gs = gpd.GeoSeries(shapely.geometry.Polygon(np.c_[box_lon,box_lat]), crs='EPSG:4326')\nregion_gdf = gpd.GeoDataFrame(geometry=region_gs).to_crs('EPSG:3857')\natl06 = s3_retrieve(atl06_granule, polygon=region_gdf)","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Compare SlideRule and Atlas Science Algorithm Software (ASAS) Results","metadata":{"trusted":true}},{"cell_type":"code","source":"# We can now compare the default processing pipeline results from Atlas Science Algorithm Software (ASAS) to the SlideRule result\n# Create Elevation Plot\nfig,ax = plt.subplots(num=1, ncols=6, sharey=True, figsize=(12, 6))\nlocator = mdates.AutoDateLocator(minticks=3, maxticks=7)\nformatter = mdates.ConciseDateFormatter(locator)\n\n# Plot Elevations for each track\ntracks = dict(gt1l=10,gt1r=20,gt2l=30,gt2r=40,gt3l=50,gt3r=60)\nfor s,gt in enumerate(tracks.keys()):\n    sr = gdf[gdf[\"gt\"] == tracks[gt]]\n    asas = atl06[(atl06[\"gt\"] == tracks[gt]) &\n        (atl06[\"h_mean\"] < 1e38) &\n        (atl06[\"segment_id\"] >= sr[\"segment_id\"][0]) &\n        (atl06[\"segment_id\"] <= sr[\"segment_id\"][-1])]\n    ax[s].set_title(gt)\n    ax[s].plot(sr.index.values, sr[\"h_mean\"].values, zorder=1,\n        linewidth=1.0, color='mediumseagreen', label='SlideRule')\n    ax[s].plot(asas.index.values, asas[\"h_mean\"].values, zorder=0,\n        linewidth=1.0, color='darkorchid', label='ASAS')\n    ax[s].xaxis.set_major_locator(locator)\n    ax[s].xaxis.set_major_formatter(formatter)\n\n# add labels and legends\nax[0].set_ylabel('Height Above WGS84 Ellipsoid')\nlgd = ax[0].legend(loc=3,frameon=False)\nlgd.get_frame().set_alpha(1.0)\nfor line in lgd.get_lines():\n    line.set_linewidth(6)\n\n# Add common title above all plots\nfig.suptitle('Laser Tracks', fontsize=14, y=1.02)\n\n# Add label below x-axis to indicate units\nfig.text(0.5, 0.02, 'Time (seconds)', ha='center', fontsize=12)\n\n# Show Plot\nplt.show()","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%matplotlib widget # (optional) - to view x,y locations on plot","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Map Plot","metadata":{"trusted":true}},{"cell_type":"code","source":"# Create PlateCarree Plot\nfig,ax1 = plt.subplots(num=None, figsize=(12, 6))\n################################\n# add global plot\n################################\nworld = gpd.read_file(\"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\") # updated link\nworld.plot(ax=ax1, color='0.8', edgecolor='black')\ngdf.plot(ax=ax1, marker='o', color='red', markersize=2.5, zorder=3)\nax1.set_title(\"SlideRule Global Reference\")\n\n# Plot locations of each track\ntracks = dict(gt1l=10,gt1r=20,gt2l=30,gt2r=40,gt3l=50,gt3r=60)\nfor s,gt in enumerate(tracks.keys()):\n    sr = gdf[gdf[\"gt\"] == tracks[gt]]\n    sr.plot(ax=ax1, marker='o', color='red', markersize=2.5, zorder=3)\n\n# Plot Bounding Box\nax1.plot(box_lon, box_lat, linewidth=1.5, color='blue', zorder=2)\n\n# x and y limits, axis = equal\nax1.set_xlim(-180,180)\nax1.set_ylim(-90,90)\nax1.set_aspect('equal', adjustable='box')\nax1.set_xlabel('Longitude (Â°)')\nax1.set_ylabel('Latitude (Â°)')\n# show plot\nplt.show()","metadata":{"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}